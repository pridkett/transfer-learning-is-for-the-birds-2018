{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transfer Learning is for the Birds\n",
    "\n",
    "Patrick Wagstrom <patrick@wagstrom.net>\n",
    "\n",
    "June 2018\n",
    "\n",
    "## Project Abstract\n",
    "\n",
    "One of the most popular applications of deep learning is for image classification. To get a truly great classifier, most applications require networks with dozen of different layers that may take weeks to train on a distributed cluster of GPUs. This cost makes the prospect of an individual training a high accuracy custom classifier daunting, at best. However, there is another way. Transfer learning with deep learning neural networks allows you to take advantage of most of the feature detection inherent in a complex deep learning neural network without the extensive training times. In this talk I'll share the beginning of training and collecting data for a custom classifier in a different domain - identification of common birds. It will cover the basics of neural networks, transfer learning, and show how to apply transfer learning to pre-trained image classification networks from Google to achieve high precision classifiers with small amounts of training time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Project Background\n",
    "This is a simple project that I'm using to try and generate some models to automatically classify the different birds that visit the various feeders in my yard.\n",
    "\n",
    "Useful references:\n",
    "* https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\n",
    "* https://github.com/tzutalin/labelImg\n",
    "* https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3\n",
    "* https://github.com/datitran/raccoon_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/amazon deeplens.png\" width=\"90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/tasks_2x.png\" width=\"20%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<p style=\"border: 1px solid #ccc; background-color: #ffe; font-size: 80%; padding: 1ex; text-align: center;\">In the 60s, Marvin Minsky assigned a couple of undergrads to spend the summer programming a computer to use a camera to identify objects in a scene. He figured they'd have the problem solved by the end of the summer. Half a century later, we're still working on it.</p>\n",
    "<p>From: https://xkcd.com/1425/</p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Four General Problems in AI\n",
    "\n",
    "* Regression\n",
    "* Clustering\n",
    "* Dimensionality Reduction\n",
    "* Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two General Data Strategies\n",
    "\n",
    "* Supervised\n",
    "* Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This Problem is Supervised Classification\n",
    "\n",
    "We are trying to classify an image according to the species of bird(s) in the image.\n",
    "\n",
    "It is likely that all of the feeder bird species in Connecticut have already been discovered, so we are working with an established taxonomy. Our classifiecations should fit into this established taxonomy, therefore we will use supervised (labeled) training data.\n",
    "\n",
    "This is a perfect use case for a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inception\n",
    "\n",
    "Google has been really good about releasing their models. One of those robust is called \"Inception\", which, if I were to train myself would cost nearly $100,000. I'm not *that interested* in seeing the birds at my feeders. Nor do I have the individual skill to build such a network.\n",
    "\n",
    "<img src=\"images/inception architecture.png\" style=\"margin-left: auto; margin-right: auto;\">\n",
    "<!-- image from: https://hackathonprojects.files.wordpress.com/2016/09/74911-image03.png via https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/ -->\n",
    "\n",
    "Sometimes the art of discovering appropriate neural network topologies is called \"graduate student descent\". It's not trivial and it's not always claer how to architect these networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quick Inception Recognizer Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generally Available Data Sets\n",
    "\n",
    "\n",
    "Wah et. al. compiled the [Caltech-UCSD Birds 200-2011 dataset](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html). It contains 200 different tagged bird species with bounding boxes! This should kickstart my model. Plus, it's well studied and people have built classifiers on the data before.\n",
    "\n",
    "**Citation:** Wah C., Branson S., Welinder P., Perona P., Belongie S. “The Caltech-UCSD Birds-200-2011 Dataset.” Computation & Neural Systems Technical Report, CNS-TR-2011-001. [[PDF Download](http://www.vision.caltech.edu/visipedia/papers/CUB_200_2011.pdf)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "from typing import Mapping, Any\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "CUB_DATA_DIR = \"CUB/CUB_200_2011\"\n",
    "\n",
    "test_train = pd.read_table(os.path.join(CUB_DATA_DIR, \"train_test_split.txt\"), names=[\"id\", \"set\"], sep=\" \")\n",
    "image_classes = pd.read_table(os.path.join(CUB_DATA_DIR, \"image_class_labels.txt\"), names=[\"id\", \"class_id\"], sep=\" \")\n",
    "classes = pd.read_table(os.path.join(CUB_DATA_DIR, \"classes.txt\"), names=[\"class_id\", \"class_name\"], sep=\" \")\n",
    "images = pd.read_table(os.path.join(CUB_DATA_DIR, \"images.txt\"), names=[\"id\", \"filename\"], sep=\" \")\n",
    "bounding_boxes = pd.read_table(os.path.join(CUB_DATA_DIR, \"bounding_boxes.txt\"), names=[\"id\", \"bb_x\", \"bb_y\", \"bb_width\", \"bb_height\"], sep=\" \")\n",
    "images = images.merge(test_train, on=\"id\")\n",
    "images = images.merge(image_classes, on=\"id\")\n",
    "images = images.merge(bounding_boxes, on=\"id\")\n",
    "images = images.merge(classes, on=\"class_id\")\n",
    "images[\"filename\"] = images[\"filename\"].map(lambda x: os.path.join(CUB_DATA_DIR, \"images\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def show_row(row: Mapping[str, Any]):\n",
    "    im = np.array(Image.open(row[\"filename\"]), dtype=np.uint8)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig,ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(im)\n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((row[\"bb_x\"], row[\"bb_y\"]),\n",
    "                             row[\"bb_width\"], row[\"bb_height\"],\n",
    "                             linewidth=3,edgecolor='r',facecolor='none')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    plt.title(row[\"class_name\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>set</th>\n",
       "      <th>class_id</th>\n",
       "      <th>bb_x</th>\n",
       "      <th>bb_y</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_height</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CUB/CUB_200_2011/images/001.Black_footed_Albat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CUB/CUB_200_2011/images/001.Black_footed_Albat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CUB/CUB_200_2011/images/001.Black_footed_Albat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CUB/CUB_200_2011/images/001.Black_footed_Albat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CUB/CUB_200_2011/images/001.Black_footed_Albat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           filename  set  class_id  \\\n",
       "0   1  CUB/CUB_200_2011/images/001.Black_footed_Albat...    0         1   \n",
       "1   2  CUB/CUB_200_2011/images/001.Black_footed_Albat...    1         1   \n",
       "2   3  CUB/CUB_200_2011/images/001.Black_footed_Albat...    0         1   \n",
       "3   4  CUB/CUB_200_2011/images/001.Black_footed_Albat...    1         1   \n",
       "4   5  CUB/CUB_200_2011/images/001.Black_footed_Albat...    1         1   \n",
       "\n",
       "    bb_x   bb_y  bb_width  bb_height                  class_name  \n",
       "0   60.0   27.0     325.0      304.0  001.Black_footed_Albatross  \n",
       "1  139.0   30.0     153.0      264.0  001.Black_footed_Albatross  \n",
       "2   14.0  112.0     388.0      186.0  001.Black_footed_Albatross  \n",
       "3  112.0   90.0     255.0      242.0  001.Black_footed_Albatross  \n",
       "4   70.0   50.0     134.0      303.0  001.Black_footed_Albatross  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generally Available Data Sets\n",
    "\n",
    "Using widgets in a Jupyter notebook, we can browse around through the images in the dataset. What we quickly see is that the CUB dataset isn't going to be super useful. Although there are good classifiers for it, I don't have many white pelicans or green kingfishers visiting my feeders in Connecticut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23ead8464a345e8a960c80ef71f55fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5893, description='i', max=11787), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def slider_plot(i):\n",
    "    show_row(images.iloc[[i]].squeeze())\n",
    "\n",
    "slider = interact(slider_plot, i=(0, images.shape[0]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Capturing Your Own Data\n",
    "\n",
    "<center><video id=\"sampleMovie\" src=\"data/video/IMG_6885.m4v\" width=\"85%\" controls style=\"margin-left: auto; margin-right: auto; margin-top: 2em;\"></video></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Capturing Your Own Data\n",
    "\n",
    "One of the hardest things about doing machine learning is training data. There are entire companies built around making this process easier, such as Figure Eight. However, this is a small project, so we can _try_ to collect some of the data ourselves. In a completely unscientific manner, I took my iPhone and took a video of my bird feeders when I saw there were birds at the feeder.\n",
    "\n",
    "On my iPhone I capture these videos at 1080p60. There's probably a case to be made for capturing at 4k30 (which is the highest resolution my iPhone 7 supports) as we're not going to label each and every frame of the data. There's too much similarity between the frames. The first step is to extract the still frames from the video. To do this let's use the standby of `ffmpeg` and convert the video into PNG files, which gives a higher quality image. This script will take all of the `MOV` and `m4v` files in a directory and slice them up for you. \n",
    "\n",
    "```bash\n",
    "for x in *.{MOV,m4v}; do\n",
    "    EXT=\"${x##*.}\"\n",
    "    BASENAME=\"${x%.*}\"\n",
    "    ffmpeg -i $x -vf \"select=not(mod(n\\,50))\"\\\n",
    "                 -vsync vfr -f image2 ${BASENAME}_%05d.png\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Labeling the Data\n",
    "\n",
    "Most image classifiers are _supervised_, which means I need to label my data. This is where the [labelImg](https://github.com/tzutalin/labelImg) project comes in handy by providing a GUI to quickly label data. I did most of this over about an hour.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/labeling.png\" width=\"70%\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Splitting Test/Train\n",
    "\n",
    "Typically you should split your data into something like a 70/30 split for test train. This gave me 149 training images and 77 test images. A pretty small dataset.\n",
    "\n",
    "```bash\n",
    "for x in *.png; do\n",
    "  if [ $(( $RANDOM % 10)) -ge 7 ]; then\n",
    "    BASENAME=\"${x%.*}\"\n",
    "    mv $BASENAME.png ../test\n",
    "    mv $BASENAME.xml ../test\n",
    "  fi\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Tiny Bit About Transfer Learning\n",
    "\n",
    "Transfer Learning allows us to use knowledge (i.e. parameters) from one problem an apply it to another related problem. This is particularly useful when the related problem has very little training data, which is the case with my bird classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Three Different Model Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Working off high resolution images isn't a better thing. Here it caused challenges with computation time and model detection. The model could only detect 300 objects in an image, and when looking for very small items in an image, this caused a lot of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Variation of training data was also problematic. I only had a limited number of pieces of training video and most frames were similar to one another. Need an automated camera to capture more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you just need to sleep on it. Go back again later, look at your results, and you'll get insight into what went wrong."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "rise": {
   "auto_select": "code",
   "auto_select_fragment": false,
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
